"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.dataReducer = void 0;
const dataActions_1 = require("./dataActions");
const getDataStreamStore_1 = require("./getDataStreamStore");
const caching_1 = require("./caching/caching");
const mergeHistoricalRequests_1 = require("./mergeHistoricalRequests");
const time_1 = require("../../common/time");
/**
 * Data Reducer
 *
 * Manages error status, loading status, and indexed data points
 */
const dataReducer = (state = {}, action) => {
    var _a, _b, _c, _d, _e, _f, _g, _h, _j, _k, _l, _m, _o, _p, _q, _r, _s, _t;
    let outGoingrequests = 0;
    switch (action.type) {
        case dataActions_1.REQUEST: {
            const { id, resolution, aggregationType, start, end, fetchFromStartToEnd, } = action.payload;
            const streamStore = (0, getDataStreamStore_1.getDataStreamStore)(id, resolution, state, aggregationType);
            const dataCache = streamStore != null ? streamStore.dataCache : caching_1.EMPTY_CACHE;
            const requestCache = streamStore != null ? streamStore.requestCache : caching_1.EMPTY_CACHE;
            const existingRequestHistory = streamStore
                ? streamStore.requestHistory
                : [];
            // We only consider it loading if data has not been requested before, or if it's already loading.
            const isLoading = streamStore == null || streamStore.isLoading;
            const numericResolution = (0, time_1.parseDuration)(resolution);
            const newStreamStore = {
                ...streamStore,
                resolution: numericResolution,
                aggregationType: aggregationType,
                requestHistory: fetchFromStartToEnd
                    ? (0, mergeHistoricalRequests_1.mergeHistoricalRequests)(existingRequestHistory, {
                        start,
                        end,
                        requestedAt: new Date(Date.now()), // Date.now utilized in this funny way to assist mocking in the unit tests
                    })
                    : existingRequestHistory,
                dataCache,
                requestCache: fetchFromStartToEnd
                    ? (0, caching_1.addToDataPointCache)({
                        cache: requestCache,
                        start,
                        end,
                    })
                    : requestCache,
                id,
                isLoading,
                isRefreshing: true,
                numOutgoingRequests: ++outGoingrequests,
            };
            const newResolutions = numericResolution != 0 && aggregationType
                ? {
                    ...(_a = state[id]) === null || _a === void 0 ? void 0 : _a.resolutions,
                    [numericResolution]: {
                        ...(_c = (_b = state[id]) === null || _b === void 0 ? void 0 : _b.resolutions) === null || _c === void 0 ? void 0 : _c[numericResolution],
                        [aggregationType]: newStreamStore,
                    },
                }
                : ((_d = state[id]) === null || _d === void 0 ? void 0 : _d.resolutions) || undefined;
            const newRawData = numericResolution === 0
                ? { ...(_e = state[id]) === null || _e === void 0 ? void 0 : _e.rawData, ...newStreamStore }
                : ((_f = state[id]) === null || _f === void 0 ? void 0 : _f.rawData) || undefined;
            return {
                ...state,
                [id]: {
                    ...state[id],
                    resolutions: newResolutions,
                    rawData: newRawData,
                },
            };
        }
        case dataActions_1.SUCCESS: {
            const { id, data: dataStream, first, last, requestInformation, } = action.payload;
            const { aggregationType, fetchFromStartToEnd, fetchMostRecentBeforeEnd, fetchMostRecentBeforeStart, } = requestInformation;
            const streamStore = (0, getDataStreamStore_1.getDataStreamStore)(id, dataStream.resolution, state, aggregationType);
            // Updating request cache is a hack to deal with latest value update
            // TODO: clean this to one single source of truth cache
            const requestCache = streamStore != null ? streamStore.requestCache : caching_1.EMPTY_CACHE;
            // We always want data in ascending order in the cache
            const sortedData = dataStream.data.sort((a, b) => a.x - b.x);
            /**
             * Based on the type of request, determine the actual range requested.
             *
             * For instance, when we fetch latest value, we stop looking for data when we find the first point, and potentially seek beyond the start of the viewport.
             * This must be taken into account.
             */
            let intervalStart = first;
            // start the interval from the returned data point to avoid over-caching
            // if there is no data point it's fine to cache the entire interval
            if ((fetchMostRecentBeforeStart || fetchMostRecentBeforeEnd) &&
                sortedData.length > 0) {
                intervalStart = new Date(sortedData[0].x);
            }
            const updatedDataCache = (0, caching_1.addToDataPointCache)({
                start: intervalStart,
                end: last,
                data: sortedData,
                cache: (streamStore && streamStore.dataCache) || caching_1.EMPTY_CACHE,
            });
            const existingRequestHistory = streamStore
                ? streamStore.requestHistory
                : [];
            // eslint-disable-next-line @typescript-eslint/no-unused-vars
            const { data, ...restOfDataStream } = dataStream;
            const noOfOutGoingrequest = --outGoingrequests;
            const newStreamStore = {
                ...streamStore,
                ...restOfDataStream,
                requestHistory: (0, mergeHistoricalRequests_1.mergeHistoricalRequests)(existingRequestHistory, {
                    start: intervalStart,
                    end: last,
                    requestedAt: new Date(Date.now()), // Date.now utilized in this funny way to assist mocking in the unit tests
                }),
                requestCache: !fetchFromStartToEnd
                    ? (0, caching_1.addToDataPointCache)({
                        cache: requestCache,
                        start: intervalStart,
                        end: last,
                    })
                    : requestCache,
                dataCache: updatedDataCache,
                isLoading: false,
                numOutgoingRequests: noOfOutGoingrequest,
                isRefreshing: noOfOutGoingrequest > 0,
                error: undefined,
            };
            const newResolutions = dataStream.resolution != 0 && aggregationType
                ? {
                    ...(_g = state[id]) === null || _g === void 0 ? void 0 : _g.resolutions,
                    [dataStream.resolution]: {
                        ...(_j = (_h = state[id]) === null || _h === void 0 ? void 0 : _h.resolutions) === null || _j === void 0 ? void 0 : _j[dataStream.resolution],
                        [aggregationType]: newStreamStore,
                    },
                }
                : ((_k = state[id]) === null || _k === void 0 ? void 0 : _k.resolutions) || undefined;
            const newRawData = dataStream.resolution === 0
                ? { ...(_l = state[id]) === null || _l === void 0 ? void 0 : _l.rawData, ...newStreamStore }
                : ((_m = state[id]) === null || _m === void 0 ? void 0 : _m.rawData) || undefined;
            return {
                ...state,
                [id]: {
                    ...state[id],
                    resolutions: newResolutions,
                    rawData: newRawData,
                },
            };
        }
        case dataActions_1.ERROR: {
            const { id, error, resolution, aggregationType } = action.payload;
            const streamStore = (0, getDataStreamStore_1.getDataStreamStore)(id, resolution, state, aggregationType);
            const newStreamStore = {
                ...streamStore,
                resolution,
                aggregationType,
                requestHistory: streamStore ? streamStore.requestHistory : [],
                dataCache: (streamStore && streamStore.dataCache) || caching_1.EMPTY_CACHE,
                requestCache: (streamStore && streamStore.requestCache) || caching_1.EMPTY_CACHE,
                id,
                error,
                isLoading: false,
                isRefreshing: false,
                numOutgoingRequests: --outGoingrequests,
            };
            const newResolutions = aggregationType
                ? {
                    ...(_o = state[id]) === null || _o === void 0 ? void 0 : _o.resolutions,
                    [resolution]: {
                        ...(_q = (_p = state[id]) === null || _p === void 0 ? void 0 : _p.resolutions) === null || _q === void 0 ? void 0 : _q[resolution],
                        [aggregationType]: newStreamStore,
                    },
                }
                : ((_r = state[id]) === null || _r === void 0 ? void 0 : _r.resolutions) || undefined;
            const newRawData = !aggregationType
                ? { ...(_s = state[id]) === null || _s === void 0 ? void 0 : _s.rawData, ...newStreamStore }
                : ((_t = state[id]) === null || _t === void 0 ? void 0 : _t.rawData) || undefined;
            return {
                ...state,
                [id]: {
                    ...state[id],
                    resolutions: newResolutions,
                    rawData: newRawData,
                },
            };
        }
        default: {
            return state;
        }
    }
};
exports.dataReducer = dataReducer;
